<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Learn how to get started with the {ino} package.
">
<title>Introduction • ino</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Introduction">
<meta property="og:description" content="Learn how to get started with the {ino} package.
">
<meta property="og:image" content="https://loelschlaeger.de/ino/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">ino</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item">
  <a class="nav-link" href="../articles/ino.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/example_hmm.html">Example: Hidden Markov Model</a>
    <a class="dropdown-item" href="../articles/example_probit.html">Example: Probit Model</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/loelschlaeger/ino/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Introduction</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/loelschlaeger/ino/blob/HEAD/vignettes/ino.Rmd" class="external-link"><code>vignettes/ino.Rmd</code></a></small>
      <div class="d-none name"><code>ino.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="motivation">Motivation<a class="anchor" aria-label="anchor" href="#motivation"></a>
</h2>
<p>Optimization is of great relevance in many fields, including finance
(portfolio optimization), engineering (minimizing air resistance), and
statistics (likelihood maximization for model fitting). Often, the
optimization problem at hand cannot be solved analytically, for example
when explicit formulas for gradient or Hessian are not available. In
these cases, numerical optimization algorithms are helpful. They
iteratively explore the parameter space, guaranteeing to improve the
function value over each iteration, and eventually converge to a point
where no more improvements can be made <span class="citation">(<a href="#ref-Bonnans:2006" role="doc-biblioref">Bonnans et al.
2006</a>)</span>. In R, several functions are available that can be
applied to numerically solve optimization problems, including (quasi)
Newton (<code><a href="https://rdrr.io/r/stats/nlm.html" class="external-link">stats::nlm()</a></code>, <code><a href="https://rdrr.io/r/stats/nlminb.html" class="external-link">stats::nlminb()</a></code>,
<code><a href="https://rdrr.io/r/stats/optim.html" class="external-link">stats::optim()</a></code>), direct search
(<code><a href="https://rdrr.io/pkg/pracma/man/neldermead.html" class="external-link">pracma::nelder_mead()</a></code>), and conjugate gradient methods
(<code>Rcgmin::Rcgmin()</code>). The <a href="https://CRAN.R-project.org/view=Optimization" class="external-link">CRAN Task View:
Optimization and Mathematical Programming</a> provides a comprehensive
list of packages for solving optimization problems.</p>
<p>One thing that all of these numerical optimizers have in common is
that initial parameter values must be specified, i.e., the point from
where the optimization is started. Optimization theory <span class="citation">(<a href="#ref-Nocedal:2006" role="doc-biblioref">Nocedal and Wright 2006</a>)</span> states that the
choice of an initial point has a large influence on the optimization
result, in particular convergence time and rate. In general, starting in
areas of function saturation increases computation time, starting in
areas of non-concavity leads to convergence problems or convergence to
local rather than global optima. Consequently, numerical optimization
can be facilitated by</p>
<ol style="list-style-type: decimal">
<li><p>analyzing the initialization effect for the optimization problem
at hand and</p></li>
<li><p>putting effort on identifying good starting values.</p></li>
</ol>
<p>However, it is generally unclear what good initial values are and how
they might affect the optimization. Therefore, the purpose of the
<a href="https://github.com/loelschlaeger/ino" class="external-link">ino</a> R package<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;&lt;em&gt;ino&lt;/em&gt; is an acronym for
&lt;strong&gt;&lt;em&gt;i&lt;/em&gt;&lt;/strong&gt;nitialization of
&lt;strong&gt;&lt;em&gt;n&lt;/em&gt;&lt;/strong&gt;umerical
&lt;strong&gt;&lt;em&gt;o&lt;/em&gt;&lt;/strong&gt;ptimization.&lt;/p&gt;"><sup>1</sup></a> is to provide a comprehensive toolbox
for</p>
<ol style="list-style-type: decimal">
<li><p>evaluating the effect of the initial values on the
optimization,</p></li>
<li><p>comparing different initialization strategies,</p></li>
<li><p>and comparing different optimizers.</p></li>
</ol>
</div>
<div class="section level2">
<h2 id="package-functionality">Package functionality<a class="anchor" aria-label="anchor" href="#package-functionality"></a>
</h2>
<p>To specify an optimization problem in <a href="https://github.com/loelschlaeger/ino" class="external-link">ino</a>, we use an
object-oriented framework based on the <a href="https://r6.r-lib.org" class="external-link">R6</a> package <span class="citation">(<a href="#ref-Chang:2021" role="doc-biblioref">Chang
2021</a>)</span>. The general workflow is to first create a
<code>Nop</code> object<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;&lt;em&gt;Nop&lt;/em&gt; is an acronym for
&lt;strong&gt;&lt;em&gt;n&lt;/em&gt;&lt;/strong&gt;umerical
&lt;strong&gt;&lt;em&gt;o&lt;/em&gt;&lt;/strong&gt;ptimization
&lt;strong&gt;&lt;em&gt;p&lt;/em&gt;&lt;/strong&gt;roblem.&lt;/p&gt;"><sup>2</sup></a>, and then apply methods to change the
attributes of that object, e.g., to optimize the function and
investigate the optimization results:</p>
<ul>
<li><p>The starting point for working with <a href="https://github.com/loelschlaeger/ino" class="external-link">ino</a> is to
initialize a <code>Nop</code> object via
<code>object &lt;- Nop$new()</code>.</p></li>
<li><p>Next, use the method <code>$set_optimizer()</code> to define one
or more numerical optimizer.</p></li>
<li><p>Then, <code>$evaluate()</code> evaluates and
<code>$optimize()</code> optimizes the objective function.</p></li>
<li><p>For analyzing the results, <code>$optima()</code> provides an
overview of all identified optima, and the <code>$plot()</code> and
<code>$summary()</code> methods summarize the optimization
runs.</p></li>
<li><p>The methods <code>$standardize()</code> and
<code>$reduce()</code> are available to advantageously transform the
optimization problem.</p></li>
</ul>
<p>We illustrate these methods in the following application.</p>
</div>
<div class="section level2">
<h2 id="workflow">Workflow<a class="anchor" aria-label="anchor" href="#workflow"></a>
</h2>
<p>We demonstrate the basic <a href="https://github.com/loelschlaeger/ino" class="external-link">ino</a> workflow in the context
of likelihood maximization, where we fit a two-class Gaussian mixture
model to Geyser eruption times from the popular <code>faithful</code>
data set that is provided via base R.</p>
<blockquote>
<p><strong>Remark:</strong> Optimization in this example is very fast.
This is because the data set is relatively small and we consider a model
with two classes only. Therefore, it might not seem relevant to be
concerned about initialization here. However, the problem scales:
optimization time will rise with more data and more parameters, in which
case initialization becomes a greater issue, see for example <span class="citation">Shireman, Steinley, and Brusco (<a href="#ref-Shireman:2017" role="doc-biblioref">2017</a>)</span>.
Additionally, we will see that even this simple optimization problem
suffers heavily from local optima, depending on the choice of initial
values.</p>
</blockquote>
<div class="section level3">
<h3 id="the-optimization-problem">The optimization problem<a class="anchor" aria-label="anchor" href="#the-optimization-problem"></a>
</h3>
<p>The <code>faithful</code> data set contains information about
eruption times (<code>eruptions</code>) of the Old Faithful geyser in
Yellowstone National Park, Wyoming, USA.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">faithful</span><span class="op">)</span></span>
<span><span class="co">#&gt; 'data.frame':    272 obs. of  2 variables:</span></span>
<span><span class="co">#&gt;  $ eruptions: num  3.6 1.8 3.33 2.28 4.53 ...</span></span>
<span><span class="co">#&gt;  $ waiting  : num  79 54 74 62 85 55 88 85 51 85 ...</span></span></code></pre></div>
<p>The data histogram hints at two clusters with short and long eruption
times, respectively.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://ggplot2.tidyverse.org" class="external-link">"ggplot2"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">faithful</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">eruptions</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html" class="external-link">geom_histogram</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes_eval.html" class="external-link">after_stat</a></span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span>, bins <span class="op">=</span> <span class="fl">30</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">xlab</a></span><span class="op">(</span><span class="st">"eruption time (min)"</span><span class="op">)</span> </span></code></pre></div>
<p><img src="figures/ino-faithful-1.png" width="75%" style="display: block; margin: auto;"></p>
<p>For both clusters, we assume a normal distribution, such that we
consider a mixture of two Gaussian densities for modeling the overall
eruption times. The log-likelihood function is defined by</p>
<p><span class="math display">\[\begin{equation}
\ell(\boldsymbol{\theta}) = \sum_{i=1}^n \log\Big( \lambda \phi_{\mu_1,
\sigma_1^2}(x_i) + (1-\lambda)\phi_{\mu_2,\sigma_2^2} (x_i) \Big),
\end{equation}\]</span></p>
<p>where the sum goes over all observations <span class="math inline">\(1, \dots, n = 272\)</span>, <span class="math inline">\(\phi_{\mu_1, \sigma_1^2}\)</span> and <span class="math inline">\(\phi_{\mu_2, \sigma_2^2}\)</span> denote the
normal density for the first and second cluster, respectively, and <span class="math inline">\(\lambda\)</span> is the mixing proportion. The
parameter vector to be estimated is thus <span class="math inline">\(\boldsymbol{\theta} = (\mu_1, \mu_2, \sigma_1,
\sigma_2, \lambda)\)</span>. As there exists no closed-form solution for
the maximum likelihood estimator <span class="math inline">\(\boldsymbol{\theta}^* =
\arg\max_{\boldsymbol{\theta}} \ell(\boldsymbol{\theta})\)</span>, we
need numerical optimization for finding the function optimum.</p>
<p>The following function calculates the log-likelihood value given the
parameter vector <code>theta</code> and the observation vector
<code>data</code>.</p>
<blockquote>
<p><strong>Remark:</strong> We restrict the standard deviations
<code>sd</code> to be positive (via the exponential transformation) and
<code>lambda</code> to be between 0 and 1 (via the logit
transformation). The function returns the negative log-likelihood value
by default (<code>neg = TRUE</code>). This is necessary because most R
optimizers only minimize (e.g., <code><a href="https://rdrr.io/r/stats/nlm.html" class="external-link">stats::nlm</a></code>), where we can
use the fact that <span class="math inline">\(\arg\max_{\boldsymbol{\theta}}
\ell(\boldsymbol{\theta}) = \arg\min_{\boldsymbol{\theta}}
-\ell(\boldsymbol{\theta})\)</span>.</p>
</blockquote>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">normal_mixture_llk</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span>, <span class="va">data</span>, <span class="va">neg</span> <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/stopifnot.html" class="external-link">stopifnot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="op">==</span> <span class="fl">5</span><span class="op">)</span></span>
<span>  <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">theta</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span></span>
<span>  <span class="va">sd</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">theta</span><span class="op">[</span><span class="fl">3</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="va">lambda</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html" class="external-link">plogis</a></span><span class="op">(</span><span class="va">theta</span><span class="op">[</span><span class="fl">5</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="va">llk</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">lambda</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">data</span>, <span class="va">mu</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="va">sd</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">lambda</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">data</span>, <span class="va">mu</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="va">sd</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html" class="external-link">ifelse</a></span><span class="op">(</span><span class="va">neg</span>, <span class="op">-</span><span class="va">llk</span>, <span class="va">llk</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="fu">normal_mixture_llk</span><span class="op">(</span>theta <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">5</span>, data <span class="op">=</span> <span class="va">faithful</span><span class="op">$</span><span class="va">eruptions</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1069.623</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="another-optimization-approach-the-expectation-maximization-em-algorithm">Another optimization approach: the expectation-maximization (EM)
algorithm<a class="anchor" aria-label="anchor" href="#another-optimization-approach-the-expectation-maximization-em-algorithm"></a>
</h3>
<p>Solving <span class="math inline">\(\boldsymbol{\theta}^* =
\arg\max_{\boldsymbol{\theta}} \ell(\boldsymbol{\theta})\)</span>
requires numerical aid because <span class="math inline">\(\frac{\text{d}}{\text{d}\boldsymbol{\theta}}
\ell(\boldsymbol{\theta})\)</span> does not have a closed-form solution.
However, if we knew the class membership of each observation, the
optimization problem would collapse to independent maximum likelihood
estimation of two Gaussian distributions, which then can be solved
analytically. This observation motivates the so-called
expectation-maximization (EM) algorithm <span class="citation">(<a href="#ref-Dempster:1977" role="doc-biblioref">Dempster, Laird, and
Rubin 1977</a>)</span>, which iterates through the following steps:</p>
<ol style="list-style-type: decimal">
<li>Initialize <span class="math inline">\(\boldsymbol{\theta}\)</span>
and compute <span class="math inline">\(\ell(\boldsymbol{\theta})\)</span>.</li>
<li>Calculate the posterior probabilities for each observation’s class
membership, conditional on <span class="math inline">\(\boldsymbol{\theta}\)</span>.</li>
<li>Calculate the maximum likelihood estimate <span class="math inline">\(\boldsymbol{\bar{\theta}}\)</span> conditional on
the posterior probabilities from step 2.</li>
<li>Evaluate <span class="math inline">\(\ell(\boldsymbol{\bar{\theta}})\)</span>. Now stop
if the likelihood improvement <span class="math inline">\(\ell(\boldsymbol{\bar{\theta}}) -
\ell(\boldsymbol{\theta})\)</span> is smaller than some threshold
<code>epsilon</code> or some iteration limit <code>iterlim</code> is
reached. Otherwise, go back to step 2.</li>
</ol>
<p>The following function implements this algorithm, which we will
compare to standard numerical optimization below.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">em</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">normal_mixture_llk</span>, <span class="va">theta</span>, <span class="va">epsilon</span> <span class="op">=</span> <span class="fl">1e-08</span>, <span class="va">iterlim</span> <span class="op">=</span> <span class="fl">1000</span>, <span class="va">data</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">llk</span> <span class="op">&lt;-</span> <span class="fu">normal_mixture_llk</span><span class="op">(</span><span class="va">theta</span>, <span class="va">data</span>, neg <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>  <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">theta</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span></span>
<span>  <span class="va">sd</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">theta</span><span class="op">[</span><span class="fl">3</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="va">lambda</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html" class="external-link">plogis</a></span><span class="op">(</span><span class="va">theta</span><span class="op">[</span><span class="fl">5</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">iterlim</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">class_1</span> <span class="op">&lt;-</span> <span class="va">lambda</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">data</span>, <span class="va">mu</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="va">sd</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span>    <span class="va">class_2</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">lambda</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">data</span>, <span class="va">mu</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="va">sd</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span>    <span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">class_1</span> <span class="op">/</span> <span class="op">(</span><span class="va">class_1</span> <span class="op">+</span> <span class="va">class_2</span><span class="op">)</span></span>
<span>    <span class="va">lambda</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span></span>
<span>    <span class="va">mu</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">posterior</span> <span class="op">*</span> <span class="va">data</span><span class="op">)</span> <span class="op">/</span> <span class="va">lambda</span></span>
<span>    <span class="va">mu</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span> <span class="op">-</span> <span class="va">lambda</span> <span class="op">*</span> <span class="va">mu</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">lambda</span><span class="op">)</span></span>
<span>    <span class="va">sd</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">posterior</span> <span class="op">*</span> <span class="op">(</span><span class="va">data</span> <span class="op">-</span> <span class="va">mu</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">/</span> <span class="va">lambda</span><span class="op">)</span></span>
<span>    <span class="va">sd</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">posterior</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="va">data</span> <span class="op">-</span> <span class="va">mu</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">lambda</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">llk_old</span> <span class="op">&lt;-</span> <span class="va">llk</span></span>
<span>    <span class="va">theta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">sd</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html" class="external-link">qlogis</a></span><span class="op">(</span><span class="va">lambda</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">llk</span> <span class="op">&lt;-</span> <span class="fu">normal_mixture_llk</span><span class="op">(</span><span class="va">theta</span>, <span class="va">data</span>, neg <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html" class="external-link">is.na</a></span><span class="op">(</span><span class="va">llk</span><span class="op">)</span><span class="op">)</span> <span class="kw"><a href="https://rdrr.io/r/base/stop.html" class="external-link">stop</a></span><span class="op">(</span><span class="st">"fail"</span><span class="op">)</span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="va">llk</span> <span class="op">-</span> <span class="va">llk_old</span> <span class="op">&lt;</span> <span class="va">epsilon</span><span class="op">)</span> <span class="kw">break</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="st">"neg_llk"</span> <span class="op">=</span> <span class="op">-</span><span class="va">llk</span>, <span class="st">"estimate"</span> <span class="op">=</span> <span class="va">theta</span>, <span class="st">"iterations"</span> <span class="op">=</span> <span class="va">i</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h3>
<p>The optimization problem is specified as a <code>Nop</code> object
called <code>geyser</code>, where</p>
<ul>
<li>
<code>f</code> is the function to be optimized (here
<code>normal_mixture_llk</code>),</li>
<li>
<code>npar</code> specifies the length of the parameter vector over
which <code>f</code> is optimized (five in this case),</li>
<li>and <code>data</code> gives the observation vector as required by
our likelihood function.</li>
</ul>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span> <span class="op">&lt;-</span> <span class="va"><a href="../reference/Nop.html">Nop</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span></span>
<span>  f <span class="op">=</span> <span class="va">normal_mixture_llk</span>, </span>
<span>  npar <span class="op">=</span> <span class="fl">5</span>, </span>
<span>  data <span class="op">=</span> <span class="va">faithful</span><span class="op">$</span><span class="va">eruptions</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Printing the object provides a specification overview:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">geyser</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="text-decoration: underline;">Optimization problem:</span></span></span>
<span><span class="co">#&gt; - Function: normal_mixture_llk</span></span>
<span><span class="co">#&gt; - Optimize over: theta (length 5) </span></span>
<span><span class="co">#&gt; - Additional arguments: data </span></span>
<span><span class="co">#&gt; <span style="text-decoration: underline;">Numerical optimizer:</span></span></span>
<span><span class="co"><span style="text-decoration: underline;">#&gt; </span><span style="font-style: italic;">No optimizer specified yet.</span></span></span>
<span><span class="co"><span style="font-style: italic;">#&gt; </span><span style="text-decoration: underline;">Optimization results:</span></span></span>
<span><span class="co"><span style="text-decoration: underline;">#&gt; </span><span style="font-style: italic;">No results saved yet.</span></span></span>
<span><span class="co"><span style="font-style: italic;">#&gt; </span></span></span></code></pre></div>
<p>The next step concerns specifying the numerical optimizer via the
<code>$set_optimizer()</code> method.</p>
<blockquote>
<p><strong>Remark:</strong> Numerical optimizers must be specified
through the unified framework provided by the <a href="https://CRAN.R-project.org/package=optimizeR" class="external-link">{optimizeR}</a>
package <span class="citation">(<a href="#ref-Oelschl%C3%A4ger:2023" role="doc-biblioref">Oelschläger and Ötting 2023</a>)</span>. This is
necessary because there is no a priori consistency across optimization
functions in R with regard to their function inputs and outputs. This
would make it impossible to allow for arbitrary optimizers and to
compare their results, see <a href="https://github.com/loelschlaeger/optimizeR#readme" class="external-link">the {optimizeR}
README file</a> for details.</p>
</blockquote>
<p>It is possible to define any numerical optimizer implemented in R
through the {optimizeR} framework. Here, we select two of the most
popular ones, <code><a href="https://rdrr.io/r/stats/nlm.html" class="external-link">stats::nlm()</a></code> and
<code><a href="https://rdrr.io/r/stats/optim.html" class="external-link">stats::optim()</a></code>:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span></span>
<span>  <span class="fu">set_optimizer</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/optimizeR/man/define_optimizer.html" class="external-link">optimizer_nlm</a></span><span class="op">(</span><span class="op">)</span>, label <span class="op">=</span> <span class="st">"nlm"</span><span class="op">)</span><span class="op">$</span></span>
<span>  <span class="fu">set_optimizer</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/optimizeR/man/define_optimizer.html" class="external-link">optimizer_optim</a></span><span class="op">(</span><span class="op">)</span>, label <span class="op">=</span> <span class="st">"optim"</span><span class="op">)</span></span></code></pre></div>
<blockquote>
<p><strong>Remark:</strong> The previous code chunk makes use of a
technique called “method chaining” <span class="citation">(see <a href="#ref-Wickham:2019" role="doc-biblioref">Wickham 2019</a>,
ch. 14.2.1)</span>. This means that <code>geyser$set_optimizer()</code>
returns the modified <code>geyser</code> object, for which we can
specify a second optimizer by calling <code>$set_optimizer()</code>
again.</p>
</blockquote>
<p>We also want to apply the EM algorithm introduced above:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">em_optimizer</span> <span class="op">&lt;-</span> <span class="fu">optimizeR</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/optimizeR/man/define_optimizer.html" class="external-link">define_optimizer</a></span><span class="op">(</span></span>
<span>  optimizer <span class="op">=</span> <span class="va">em</span>, objective <span class="op">=</span> <span class="st">"normal_mixture_llk"</span>,</span>
<span>  initial <span class="op">=</span> <span class="st">"theta"</span>, value <span class="op">=</span> <span class="st">"neg_llk"</span>, parameter <span class="op">=</span> <span class="st">"estimate"</span></span>
<span><span class="op">)</span></span>
<span><span class="va">geyser</span><span class="op">$</span><span class="fu">set_optimizer</span><span class="op">(</span><span class="va">em_optimizer</span>, label <span class="op">=</span> <span class="st">"em"</span><span class="op">)</span></span></code></pre></div>
<p>Finally, we can validate our specification:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span><span class="fu">test</span><span class="op">(</span>verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Test configuration</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Function specified: normal_mixture_llk</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Target argument specified: theta (length 5)</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Test initial values specified: -0.84 1.6 0.33 -0.82 0.49</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Test function call</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Test function call returned a <span style="color: #0000BB;">&lt;numeric&gt;</span>.</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Return value: 1656.7</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Test optimization with `nlm`</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Test optimization returned a <span style="color: #0000BB;">&lt;list&gt;</span>.</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Return value: 421.42</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Return parameter: 7 3.49 37.15 0.13 -23.35</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Return seconds: 0.01</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Test optimization with `optim`</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Test optimization returned a <span style="color: #0000BB;">&lt;list&gt;</span>.</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Return value: 277.34</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Return parameter: 4.26 2 -0.83 -1.52 0.53</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Return seconds: 0.02</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Test optimization with `em`</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Test optimization returned a <span style="color: #0000BB;">&lt;list&gt;</span>.</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Return value: 276.36</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Return parameter: 4.27 2.02 -0.83 -1.45 0.63</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Return seconds: 0.03</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="function-evaluation">Function evaluation<a class="anchor" aria-label="anchor" href="#function-evaluation"></a>
</h3>
<p>Once the <code>Nop</code> object is specified, evaluating
<code>normal_mixture_llk</code> at some value for the parameter vector
<code>theta</code> is simple with the <code>$evaluate()</code> method,
for example:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span><span class="fu">evaluate</span><span class="op">(</span>at <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1069.623</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="function-optimization">Function optimization<a class="anchor" aria-label="anchor" href="#function-optimization"></a>
</h3>
<p>Optimization of <code>normal_mixture_llk</code> is possible with the
<code>$optimize()</code> method, for example:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span><span class="fu">optimize</span><span class="op">(</span>initial <span class="op">=</span> <span class="st">"random"</span>, which_optimizer <span class="op">=</span> <span class="st">"nlm"</span>, save_result <span class="op">=</span> <span class="cn">FALSE</span>, return_result <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; $value</span></span>
<span><span class="co">#&gt; [1] 421.417</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $parameter</span></span>
<span><span class="co">#&gt; [1]  -0.6263152   3.4877817  -0.8353112   0.1303885 -23.1685784</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $seconds</span></span>
<span><span class="co">#&gt; [1] 0.007810354</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $initial</span></span>
<span><span class="co">#&gt; [1] -0.6264538  0.1836433 -0.8356286  1.5952808  0.3295078</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $gradient</span></span>
<span><span class="co">#&gt; [1] 0.000000e+00 6.716353e-05 0.000000e+00 1.141416e-04 2.453470e-08</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $code</span></span>
<span><span class="co">#&gt; [1] 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $iterations</span></span>
<span><span class="co">#&gt; [1] 36</span></span></code></pre></div>
<p>The method arguments are:</p>
<ul>
<li><p><code>initial = "random"</code> for random starting values drawn
from a standard normal distribution,</p></li>
<li><p><code>which_optimizer = "nlm"</code> for optimization with the
above specified <code><a href="https://rdrr.io/r/stats/nlm.html" class="external-link">stats::nlm</a></code> optimizer,</p></li>
<li><p><code>save_result = FALSE</code> to not save the optimization
result inside the <code>geyser</code> object (see below),</p></li>
<li><p>and <code>return_results = TRUE</code> to directly return the
optimization result instead.</p></li>
</ul>
<p>The return value is a <code>list</code> of:</p>
<ul>
<li><p><code>value</code>, the optimum function value,</p></li>
<li><p><code>parameter</code>, the parameter vector where
<code>value</code> is obtained,</p></li>
<li><p><code>seconds</code>, the estimation time in seconds,</p></li>
<li><p><code>initial</code>, the starting parameter vector for the
optimization,</p></li>
<li><p>and <code>gradient</code>, <code>code</code>, and
<code>iterations</code>, which are outputs specific to the
<code><a href="https://rdrr.io/r/stats/nlm.html" class="external-link">stats::nlm</a></code> optimizer.</p></li>
</ul>
</div>
<div class="section level3">
<h3 id="initialization-effect">Initialization effect<a class="anchor" aria-label="anchor" href="#initialization-effect"></a>
</h3>
<p>We are interested in the effect of the starting values on the
optimization, i.e., whether different initial values lead to different
results. We therefore optimize the likelihood function
<code>runs = 100</code> times at different random starting points
(<code>initial = "random"</code>) and compare the identified optima:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span><span class="fu">optimize</span><span class="op">(</span>initial <span class="op">=</span> <span class="st">"random"</span>, runs <span class="op">=</span> <span class="fl">100</span>, label <span class="op">=</span> <span class="st">"random"</span>, save_results <span class="op">=</span> <span class="cn">TRUE</span>, seed <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p>Note:</p>
<ol style="list-style-type: decimal">
<li>We label the optimization results with
<code>label = "random"</code>, which will be useful later for
comparisons.</li>
<li>We set <code>save_results = TRUE</code> to save the optimization
results inside the <code>geyser</code> object (so that we can use the
<code>$optima()</code>, <code>$summary()</code>, and
<code>$plot()</code> methods for comparisons, see below).</li>
<li>The <code>seed = 1</code> argument ensures reproducibility.</li>
</ol>
<p>The <code>$optima()</code> method provides an overview of the
identified optima. Here, we ignore any decimal places by setting
<code>digits = 0</code> and sort by the optimum function
<code>value</code>:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span><span class="fu">optima</span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">0</span>, sort_by <span class="op">=</span> <span class="st">"value"</span><span class="op">)</span></span>
<span><span class="co">#&gt;    value frequency</span></span>
<span><span class="co">#&gt; 1    276       105</span></span>
<span><span class="co">#&gt; 2    277         1</span></span>
<span><span class="co">#&gt; 3    283         1</span></span>
<span><span class="co">#&gt; 4    290         1</span></span>
<span><span class="co">#&gt; 5    294         1</span></span>
<span><span class="co">#&gt; 6    296         1</span></span>
<span><span class="co">#&gt; 7    316         1</span></span>
<span><span class="co">#&gt; 8    323         1</span></span>
<span><span class="co">#&gt; 9    355         1</span></span>
<span><span class="co">#&gt; 10   364         1</span></span>
<span><span class="co">#&gt; 11   368         1</span></span>
<span><span class="co">#&gt; 12   370         1</span></span>
<span><span class="co">#&gt; 13   372         1</span></span>
<span><span class="co">#&gt; 14   374         1</span></span>
<span><span class="co">#&gt; 15   389         1</span></span>
<span><span class="co">#&gt; 16   395         2</span></span>
<span><span class="co">#&gt; 17   397         1</span></span>
<span><span class="co">#&gt; 18   400         1</span></span>
<span><span class="co">#&gt; 19   402         1</span></span>
<span><span class="co">#&gt; 20   406         2</span></span>
<span><span class="co">#&gt; 21   415         1</span></span>
<span><span class="co">#&gt; 22   419         2</span></span>
<span><span class="co">#&gt; 23   420         1</span></span>
<span><span class="co">#&gt; 24   421       163</span></span>
<span><span class="co">#&gt; 25  &lt;NA&gt;         7</span></span></code></pre></div>
<p>The 100 optimization runs with 3 optimizers using random starting
values led to 24 different optima (minima in this case, because we
minimized <code>normal_mixture_llk()</code>), while 7 optimization runs
failed. We therefore can already deduce that the initial values have a
huge impact on the optimization result.</p>
<p>Looking at this overview optimizer-wise reveals that the
<code><a href="https://rdrr.io/r/stats/optim.html" class="external-link">stats::optim</a></code> optimizer seems to be most vulnerable to local
optima:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span><span class="fu">optima</span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">0</span>, sort_by <span class="op">=</span> <span class="st">"value"</span>, which_optimizer <span class="op">=</span> <span class="st">"nlm"</span><span class="op">)</span></span>
<span><span class="co">#&gt;   value frequency</span></span>
<span><span class="co">#&gt; 1   276        19</span></span>
<span><span class="co">#&gt; 2   370         1</span></span>
<span><span class="co">#&gt; 3   406         1</span></span>
<span><span class="co">#&gt; 4   421        79</span></span>
<span><span class="va">geyser</span><span class="op">$</span><span class="fu">optima</span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">0</span>, sort_by <span class="op">=</span> <span class="st">"value"</span>, which_optimizer <span class="op">=</span> <span class="st">"optim"</span><span class="op">)</span></span>
<span><span class="co">#&gt;    value frequency</span></span>
<span><span class="co">#&gt; 1    276         4</span></span>
<span><span class="co">#&gt; 2    277         1</span></span>
<span><span class="co">#&gt; 3    283         1</span></span>
<span><span class="co">#&gt; 4    290         1</span></span>
<span><span class="co">#&gt; 5    294         1</span></span>
<span><span class="co">#&gt; 6    296         1</span></span>
<span><span class="co">#&gt; 7    316         1</span></span>
<span><span class="co">#&gt; 8    323         1</span></span>
<span><span class="co">#&gt; 9    355         1</span></span>
<span><span class="co">#&gt; 10   364         1</span></span>
<span><span class="co">#&gt; 11   368         1</span></span>
<span><span class="co">#&gt; 12   372         1</span></span>
<span><span class="co">#&gt; 13   374         1</span></span>
<span><span class="co">#&gt; 14   389         1</span></span>
<span><span class="co">#&gt; 15   395         2</span></span>
<span><span class="co">#&gt; 16   400         1</span></span>
<span><span class="co">#&gt; 17   402         1</span></span>
<span><span class="co">#&gt; 18   406         1</span></span>
<span><span class="co">#&gt; 19   415         1</span></span>
<span><span class="co">#&gt; 20   419         2</span></span>
<span><span class="co">#&gt; 21   420         1</span></span>
<span><span class="co">#&gt; 22   421        74</span></span>
<span><span class="va">geyser</span><span class="op">$</span><span class="fu">optima</span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">0</span>, sort_by <span class="op">=</span> <span class="st">"value"</span>, which_optimizer <span class="op">=</span> <span class="st">"em"</span><span class="op">)</span></span>
<span><span class="co">#&gt;   value frequency</span></span>
<span><span class="co">#&gt; 1   276        82</span></span>
<span><span class="co">#&gt; 2   397         1</span></span>
<span><span class="co">#&gt; 3   421        10</span></span>
<span><span class="co">#&gt; 4  &lt;NA&gt;         7</span></span></code></pre></div>
<p>The two most occurring optima are 421 and 276 with total frequencies
of 163 and 105, respectively. The value 276 is the overall minimum
(potentially the global minimum), while 421 is significantly worse.</p>
<p>To compare the parameter vectors that led to these different values,
we can use the <code>$closest_parameter()</code> method. From the saved
optimization runs, it extracts the parameter vector corresponding to an
optimum closest to <code>value</code>. We consider only results from the
<code>nlm</code> optimizer here:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">mle</span> <span class="op">&lt;-</span> <span class="va">geyser</span><span class="op">$</span><span class="fu">closest_parameter</span><span class="op">(</span>value <span class="op">=</span> <span class="fl">276</span>, which_optimizer <span class="op">=</span> <span class="st">"nlm"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1]  2.02  4.27 -1.45 -0.83 -0.63</span></span>
<span><span class="co">#&gt; attr(,"run")</span></span>
<span><span class="co">#&gt; [1] 89</span></span>
<span><span class="co">#&gt; attr(,"optimizer")</span></span>
<span><span class="co">#&gt; [1] "nlm"</span></span>
<span><span class="va">geyser</span><span class="op">$</span><span class="fu">evaluate</span><span class="op">(</span>at <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html" class="external-link">as.vector</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 276.3699</span></span>
<span><span class="va">mle_run</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/attr.html" class="external-link">attr</a></span><span class="op">(</span><span class="va">mle</span>, <span class="st">"run"</span><span class="op">)</span></span>
<span><span class="op">(</span><span class="va">bad</span> <span class="op">&lt;-</span> <span class="va">geyser</span><span class="op">$</span><span class="fu">closest_parameter</span><span class="op">(</span>value <span class="op">=</span> <span class="fl">421</span>, which_optimizer <span class="op">=</span> <span class="st">"nlm"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1]  3.49  2.11  0.13 -0.09 17.49</span></span>
<span><span class="co">#&gt; attr(,"run")</span></span>
<span><span class="co">#&gt; [1] 13</span></span>
<span><span class="co">#&gt; attr(,"optimizer")</span></span>
<span><span class="co">#&gt; [1] "nlm"</span></span>
<span><span class="va">geyser</span><span class="op">$</span><span class="fu">evaluate</span><span class="op">(</span>at <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html" class="external-link">as.vector</a></span><span class="op">(</span><span class="va">bad</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 421.4176</span></span>
<span><span class="va">bad_run</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/attr.html" class="external-link">attr</a></span><span class="op">(</span><span class="va">bad</span>, <span class="st">"run"</span><span class="op">)</span></span></code></pre></div>
<p>These two parameter vectors are saved as <code>mle</code> (this shall
be our maximum likelihood estimate) and <code>bad</code> (this clearly
is a bad estimate). Two attributes show the run id and the optimizer
that led to these parameters.</p>
<p>To understand the values in terms of means, standard deviations, and
mixing proportion (i.e., in the form <span class="math inline">\(\boldsymbol{\theta} = (\mu_1, \mu_2, \sigma_1,
\sigma_2, \lambda)\)</span>), they need transformation (see above):</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">transform</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">theta</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span>, <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">theta</span><span class="op">[</span><span class="fl">3</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html" class="external-link">plogis</a></span><span class="op">(</span><span class="va">theta</span><span class="op">[</span><span class="fl">5</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">(</span><span class="va">mle</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 2.0200000 4.2700000 0.2345703 0.4360493 0.3475105</span></span>
<span><span class="op">(</span><span class="va">bad</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span><span class="va">bad</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 3.4900000 2.1100000 1.1388284 0.9139312 1.0000000</span></span></code></pre></div>
<p>The two estimates <code>mle</code> and <code>bad</code> for <span class="math inline">\(\boldsymbol{\theta}\)</span> correspond to the
following mixture densities:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mixture_density</span> <span class="op">&lt;-</span> <span class="kw">function</span> <span class="op">(</span><span class="va">data</span>, <span class="va">mu</span>, <span class="va">sd</span>, <span class="va">lambda</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">lambda</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">data</span>, <span class="va">mu</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="va">sd</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">lambda</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">data</span>, <span class="va">mu</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="va">sd</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">faithful</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">eruptions</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html" class="external-link">geom_histogram</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes_eval.html" class="external-link">after_stat</a></span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span>, bins <span class="op">=</span> <span class="fl">30</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"eruption time (min)"</span>, colour <span class="op">=</span> <span class="st">"parameter"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_function.html" class="external-link">stat_function</a></span><span class="op">(</span></span>
<span>    fun <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="fu">mixture_density</span><span class="op">(</span><span class="va">x</span>, mu <span class="op">=</span> <span class="va">mle</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span>, sd <span class="op">=</span> <span class="va">mle</span><span class="op">[</span><span class="fl">3</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>, lambda <span class="op">=</span> <span class="va">mle</span><span class="op">[</span><span class="fl">5</span><span class="op">]</span><span class="op">)</span></span>
<span>    <span class="op">}</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"mle"</span><span class="op">)</span>, linewidth <span class="op">=</span> <span class="fl">1</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_function.html" class="external-link">stat_function</a></span><span class="op">(</span></span>
<span>    fun <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="fu">mixture_density</span><span class="op">(</span><span class="va">x</span>, mu <span class="op">=</span> <span class="va">bad</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span>, sd <span class="op">=</span> <span class="va">bad</span><span class="op">[</span><span class="fl">3</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>, lambda <span class="op">=</span> <span class="va">bad</span><span class="op">[</span><span class="fl">5</span><span class="op">]</span><span class="op">)</span></span>
<span>    <span class="op">}</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"bad"</span><span class="op">)</span>, linewidth <span class="op">=</span> <span class="fl">1</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
<p><img src="figures/ino-estimated-mixtures-1.png" width="75%" style="display: block; margin: auto;"></p>
<p>The mixture defined by the <code>mle</code> parameter fits much
better than <code>bad</code>, which practically estimates only a single
class. However, the gradients at both points are close to zero, which
explains why the <code>nlm</code> optimizer terminates at both
points:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span><span class="fu">results</span><span class="op">(</span>which_run <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">mle_run</span>, <span class="va">bad_run</span><span class="op">)</span>, which_optimizer <span class="op">=</span> <span class="st">"nlm"</span>, which_element <span class="op">=</span> <span class="st">"gradient"</span><span class="op">)</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt;     gradient1     gradient2     gradient3     gradient4     gradient5 </span></span>
<span><span class="co">#&gt;  2.826051e-05 -8.066033e-08  7.162271e-06  4.604317e-06  6.532028e-07 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[2]]</span></span>
<span><span class="co">#&gt;     gradient1     gradient2     gradient3     gradient4     gradient5 </span></span>
<span><span class="co">#&gt;  2.630258e-06 -1.495794e-07 -1.724342e-07  6.247092e-07  2.660272e-07</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="custom-sampler-for-initial-values">Custom sampler for initial values<a class="anchor" aria-label="anchor" href="#custom-sampler-for-initial-values"></a>
</h3>
<p>Depending on the application and the magnitude of the parameters to
be estimated, initial values drawn from a standard normal distribution
(which is the default behavior when calling
<code>$optimize(initial = "random")</code>) may not be a good guess. We
can, however, easily modify the distribution that is used to draw the
initial values. For example, the next code snippet uses starting values
drawn from a <span class="math inline">\(\mathcal{N}(\mu = 2, \sigma =
0.5)\)</span> distribution:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">sampler</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">5</span>, mean <span class="op">=</span> <span class="fl">2</span>, sd <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">geyser</span><span class="op">$</span><span class="fu">optimize</span><span class="op">(</span>initial <span class="op">=</span> <span class="va">sampler</span>, runs <span class="op">=</span> <span class="fl">100</span>, label <span class="op">=</span> <span class="st">"custom_sampler"</span><span class="op">)</span></span></code></pre></div>
<p>To obtain the first results of these optimization runs, we can use
the <code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code> method. Note that setting
<code>which_run = "custom_sampler"</code> allows filtering, which is the
benefit of setting a <code>label</code> when calling
<code>$optimize()</code>.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">geyser</span>, which_run <span class="op">=</span> <span class="st">"custom_sampler"</span>, digits <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co">#&gt;     value                        parameter</span></span>
<span><span class="co">#&gt; 1  421.42   3.49, 2.11, 0.13, -0.16, 16.75</span></span>
<span><span class="co">#&gt; 2  421.42 3.49, -1.41, 0.13, -10.17, 16.53</span></span>
<span><span class="co">#&gt; 3  276.36  2.02, 4.27, -1.45, -0.83, -0.63</span></span>
<span><span class="co">#&gt; 4  276.36   4.27, 2.02, -0.83, -1.45, 0.63</span></span>
<span><span class="co">#&gt; 5  421.42    3.49, 5.54, 0.13, 1.79, 14.70</span></span>
<span><span class="co">#&gt; 6  276.36   4.27, 2.02, -0.83, -1.45, 0.63</span></span>
<span><span class="co">#&gt; 7  276.36   4.27, 2.02, -0.83, -1.45, 0.63</span></span>
<span><span class="co">#&gt; 8  405.72    4.33, 2.16, 0.06, -0.36, 0.70</span></span>
<span><span class="co">#&gt; 9  276.36   4.27, 2.02, -0.83, -1.45, 0.63</span></span>
<span><span class="co">#&gt; 10 276.36   4.27, 2.02, -0.83, -1.45, 0.63</span></span></code></pre></div>
<p>Again we obtain different optima (even more than before). But in
contrast, most of the runs here lead to the presumably global optimum of
276:</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span><span class="fu">optima</span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">0</span>, sort_by <span class="op">=</span> <span class="st">"value"</span>, which_run <span class="op">=</span> <span class="st">"custom_sampler"</span><span class="op">)</span></span>
<span><span class="co">#&gt;    value frequency</span></span>
<span><span class="co">#&gt; 1    276       183</span></span>
<span><span class="co">#&gt; 2    277         1</span></span>
<span><span class="co">#&gt; 3    278         1</span></span>
<span><span class="co">#&gt; 4    283         1</span></span>
<span><span class="co">#&gt; 5    288         1</span></span>
<span><span class="co">#&gt; 6    289         1</span></span>
<span><span class="co">#&gt; 7    291         1</span></span>
<span><span class="co">#&gt; 8    292         1</span></span>
<span><span class="co">#&gt; 9    295         1</span></span>
<span><span class="co">#&gt; 10   297         1</span></span>
<span><span class="co">#&gt; 11   303         1</span></span>
<span><span class="co">#&gt; 12   314         1</span></span>
<span><span class="co">#&gt; 13   316         1</span></span>
<span><span class="co">#&gt; 14   317         1</span></span>
<span><span class="co">#&gt; 15   320         1</span></span>
<span><span class="co">#&gt; 16   321         1</span></span>
<span><span class="co">#&gt; 17   329         1</span></span>
<span><span class="co">#&gt; 18   331         1</span></span>
<span><span class="co">#&gt; 19   333         1</span></span>
<span><span class="co">#&gt; 20   335         1</span></span>
<span><span class="co">#&gt; 21   337         1</span></span>
<span><span class="co">#&gt; 22   338         1</span></span>
<span><span class="co">#&gt; 23   339         1</span></span>
<span><span class="co">#&gt; 24   344         1</span></span>
<span><span class="co">#&gt; 25   347         1</span></span>
<span><span class="co">#&gt; 26   351         1</span></span>
<span><span class="co">#&gt; 27   352         1</span></span>
<span><span class="co">#&gt; 28   362         1</span></span>
<span><span class="co">#&gt; 29   368         1</span></span>
<span><span class="co">#&gt; 30   376         1</span></span>
<span><span class="co">#&gt; 31   377         1</span></span>
<span><span class="co">#&gt; 32   380         1</span></span>
<span><span class="co">#&gt; 33   390         3</span></span>
<span><span class="co">#&gt; 34   395         1</span></span>
<span><span class="co">#&gt; 35   397         1</span></span>
<span><span class="co">#&gt; 36   398         1</span></span>
<span><span class="co">#&gt; 37   401         1</span></span>
<span><span class="co">#&gt; 38   402         1</span></span>
<span><span class="co">#&gt; 39   405         1</span></span>
<span><span class="co">#&gt; 40   406         2</span></span>
<span><span class="co">#&gt; 41   407         1</span></span>
<span><span class="co">#&gt; 42   409         2</span></span>
<span><span class="co">#&gt; 43   411         3</span></span>
<span><span class="co">#&gt; 44   415         1</span></span>
<span><span class="co">#&gt; 45   416         2</span></span>
<span><span class="co">#&gt; 46   417         1</span></span>
<span><span class="co">#&gt; 47   419         1</span></span>
<span><span class="co">#&gt; 48   421        64</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="educated-guesses">Educated guesses<a class="anchor" aria-label="anchor" href="#educated-guesses"></a>
</h3>
<p>Next we make “educated guesses” about starting values that are
probably close to the global optimum. Based on the histogram above, the
means of the two normal distributions may be somewhere around 2 and 4.
We will use sets of starting values where the means are lower and larger
than 2 and 4, respectively. For the variances, we set the starting
values close to 1 (note that we use the log transformation here since we
restrict the standard deviations to be positive by using
<code><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp()</a></code> in the log-likelihood function). The starting value
for the mixing proportion shall be around 0.5. This leads to the
following 32 combinations of starting values:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mu_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1.7</span>, <span class="fl">2.3</span><span class="op">)</span></span>
<span><span class="va">mu_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4.3</span>, <span class="fl">3.7</span><span class="op">)</span></span>
<span><span class="va">sd_1</span> <span class="op">&lt;-</span> <span class="va">sd_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">0.8</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1.2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">lambda</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html" class="external-link">qlogis</a></span><span class="op">(</span><span class="fl">0.4</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html" class="external-link">qlogis</a></span><span class="op">(</span><span class="fl">0.6</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">starting_values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/asplit.html" class="external-link">asplit</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span><span class="va">mu_1</span>, <span class="va">mu_2</span>, <span class="va">sd_1</span>, <span class="va">sd_2</span>, <span class="va">lambda</span><span class="op">)</span>, MARGIN <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p>In the <code>$optimize()</code> method, instead of
<code>initial = "random"</code>, we can set <code>initial</code> to a
numeric vector of length <code>npar</code>, or, for convenience, to a
<code>list</code> of such vectors, like
<code>starting_values</code>:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span><span class="fu">optimize</span><span class="op">(</span>initial <span class="op">=</span> <span class="va">starting_values</span>, label <span class="op">=</span> <span class="st">"educated_guess"</span><span class="op">)</span></span></code></pre></div>
<p>These “educated guesses” lead to a way more stable optimization:</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span><span class="fu">optima</span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">0</span>, which_run <span class="op">=</span> <span class="st">"educated_guess"</span><span class="op">)</span></span>
<span><span class="co">#&gt;   value frequency</span></span>
<span><span class="co">#&gt; 1   276        95</span></span>
<span><span class="co">#&gt; 2   277         1</span></span></code></pre></div>
<p>For comparison, we consider a set of implausible starting values,
which leads to local optima:</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span><span class="fu">optimize</span><span class="op">(</span>initial <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">5</span><span class="op">)</span>, label <span class="op">=</span> <span class="st">"bad_guess"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">geyser</span>, which_run <span class="op">=</span> <span class="st">"bad_guess"</span><span class="op">)</span> </span>
<span><span class="co">#&gt;    value                       parameter</span></span>
<span><span class="co">#&gt; 1 421.42    3.49, 3.49, 0.13, 0.13, 0.00</span></span>
<span><span class="co">#&gt; 2 384.78 1.84, 3.64, -2.92, -0.03, -3.00</span></span>
<span><span class="co">#&gt; 3 421.42    3.49, 3.49, 0.13, 0.13, 0.00</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="standardizing-the-optimization-problem">Standardizing the optimization problem<a class="anchor" aria-label="anchor" href="#standardizing-the-optimization-problem"></a>
</h3>
<p>In some situations, it is possible to consider a standardized version
of the optimization problem, which could potentially improve the
performance of the numerical optimizer. In our example, we can
standardize the data before running the optimization via the
<code>$standardize()</code> method:</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span><span class="fu">standardize</span><span class="op">(</span><span class="st">"data"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">geyser</span><span class="op">$</span><span class="fu">get_argument</span><span class="op">(</span><span class="st">"data"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;  num [1:272] 0.0983 -1.4787 -0.1356 -1.0556 0.9158 ...</span></span></code></pre></div>
<p>To optimize the likelihood using the standardized data set, we again
use <code>$optmize()</code>, which by default uses random starting
values. Below, we will compare these results with those obtained on the
original optimization problem.</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span></span>
<span>  <span class="fu">optimize</span><span class="op">(</span>runs <span class="op">=</span> <span class="fl">100</span>, label <span class="op">=</span> <span class="st">"data_standardized"</span><span class="op">)</span><span class="op">$</span></span>
<span>  <span class="fu">reset_argument</span><span class="op">(</span><span class="st">"data"</span><span class="op">)</span></span></code></pre></div>
<p>The usage of <code>$reset_argument("data")</code> is important: to
perform further optimization runs after having applied standardized
initialization, we undo the standardization of the data and obtain the
original data set. If we would not use <code>$reset_argument()</code>,
all further optimization runs will be carried out on the standardized
data set.</p>
</div>
<div class="section level3">
<h3 id="reducing-the-optimization-problem">Reducing the optimization problem<a class="anchor" aria-label="anchor" href="#reducing-the-optimization-problem"></a>
</h3>
<p>In some situations, it is possible to first optimize a sub-problem
and use those results as an initialization for the full optimization
problem. For example, in the context of likelihood maximization, if the
data set considered shows some complex structures or is very large,
numerical optimization may become computationally costly. In such cases,
it can be beneficial to initially consider a reduced data set. The
following application of the <code>$reduce()</code> method transforms
<code>"data"</code> by selecting a proportion of 30% data points at
random:</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span><span class="fu">reduce</span><span class="op">(</span>argument_name <span class="op">=</span> <span class="st">"data"</span>, how <span class="op">=</span> <span class="st">"random"</span>, prop <span class="op">=</span> <span class="fl">0.3</span>, seed <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">geyser</span><span class="op">$</span><span class="fu">get_argument</span><span class="op">(</span><span class="st">"data"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;  num [1:82] 4.2 1.75 4.25 1.75 3.45 ...</span></span></code></pre></div>
<p>Similar to the standardizing above, calling <code>$optimize()</code>
now optimizes on the reduced data set:</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span></span>
<span>  <span class="fu">optimize</span><span class="op">(</span>runs <span class="op">=</span> <span class="fl">100</span>, label <span class="op">=</span> <span class="st">"data_subset"</span><span class="op">)</span><span class="op">$</span></span>
<span>  <span class="fu">reset_argument</span><span class="op">(</span><span class="st">"data"</span><span class="op">)</span><span class="op">$</span></span>
<span>  <span class="fu">continue</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>Again, we use <code>$reset_argument("data")</code> to obtain the
original data set. The <code>$continue()</code> method now optimizes on
the whole data set using the estimates obtained on the reduced data as
initial values.</p>
<p>In addition to selecting sub samples at random
(<code>how = "random"</code>), four other options exist via specifying
the argument <code>how</code>:</p>
<ul>
<li>
<code>"first"</code> selects the top data points,</li>
<li>
<code>"last"</code> selects the last data points,</li>
<li>
<code>"similar</code> selects similar data points based on k-means
clustering,</li>
<li>
<code>"dissimilar"</code> is similar to <code>"similar"</code> but
selects dissimilar data points.</li>
</ul>
<p>See the other two vignettes for demonstrations of these options.</p>
</div>
<div class="section level3">
<h3 id="optimization-times">Optimization times<a class="anchor" aria-label="anchor" href="#optimization-times"></a>
</h3>
<p>The <code>$plot()</code> method provides an overview of the
optimization times. Setting <code>by = "label"</code> allows for
comparison across initialization strategies, setting
<code>relative = TRUE</code> plots relative differences to the median of
the top boxplot:</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span><span class="fu">plot</span><span class="op">(</span>by <span class="op">=</span> <span class="st">"label"</span>, relative <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p><img src="figures/ino-plot-by-label-1.png" width="75%" style="display: block; margin: auto;"></p>
<p>Setting <code>by = "optimizer"</code> allows comparison across
optimizers:</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span><span class="fu">plot</span><span class="op">(</span>by <span class="op">=</span> <span class="st">"optimizer"</span>, relative <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p><img src="figures/ino-plot-by-optimizer-1.png" width="75%" style="display: block; margin: auto;"></p>
</div>
<div class="section level3">
<h3 id="the-global-optimum">The global optimum<a class="anchor" aria-label="anchor" href="#the-global-optimum"></a>
</h3>
<p>The best optimization result can be extracted via:</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span><span class="fu">best_value</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 248.98</span></span>
<span><span class="co">#&gt; attr(,"run")</span></span>
<span><span class="co">#&gt; [1] 421</span></span>
<span><span class="co">#&gt; attr(,"optimizer")</span></span>
<span><span class="co">#&gt; [1] "em"</span></span>
<span><span class="va">geyser</span><span class="op">$</span><span class="fu">best_parameter</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1]   3.53   1.75   0.11 -32.71   3.79</span></span>
<span><span class="co">#&gt; attr(,"run")</span></span>
<span><span class="co">#&gt; [1] 421</span></span>
<span><span class="co">#&gt; attr(,"optimizer")</span></span>
<span><span class="co">#&gt; [1] "em"</span></span></code></pre></div>
<p>The best function value of 248.98 is unique:</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">geyser</span><span class="op">$</span><span class="fu">optima</span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">0</span>, sort_by <span class="op">=</span> <span class="st">"value"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;   value frequency</span></span>
<span><span class="co">#&gt; 1   249         1</span></span>
<span><span class="co">#&gt; 2   276       514</span></span>
<span><span class="co">#&gt; 3   277         4</span></span>
<span><span class="co">#&gt; 4   278         1</span></span>
<span><span class="co">#&gt; 5   283         2</span></span>
<span><span class="co">#&gt; 6   288         1</span></span></code></pre></div>
<p>Furthermore, it does not produce a two-class mixture, since one class
variance is practically zero, see the output of
<code>geyser$best_parameter()</code>. We can therefore delete this
result from our <code>Nop</code> object:</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">geyser</span><span class="op">$</span><span class="fu">clear</span><span class="op">(</span>which_run <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/attr.html" class="external-link">attr</a></span><span class="op">(</span><span class="va">geyser</span><span class="op">$</span><span class="fu">best_value</span><span class="op">(</span><span class="op">)</span>, <span class="st">"run"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>The final <code>Nop</code> object then looks as follows:</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">geyser</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="text-decoration: underline;">Optimization problem:</span></span></span>
<span><span class="co">#&gt; - Function: normal_mixture_llk</span></span>
<span><span class="co">#&gt; - Optimize over: theta (length 5) </span></span>
<span><span class="co">#&gt; - Additional arguments: data </span></span>
<span><span class="co">#&gt; <span style="text-decoration: underline;">Numerical optimizer:</span></span></span>
<span><span class="co"><span style="text-decoration: underline;">#&gt; </span>- 1: nlm </span></span>
<span><span class="co">#&gt; - 2: optim </span></span>
<span><span class="co">#&gt; - 3: em </span></span>
<span><span class="co">#&gt; <span style="text-decoration: underline;">Optimization results:</span></span></span>
<span><span class="co"><span style="text-decoration: underline;">#&gt; </span>- Total runs (comparable): 433 (332)</span></span>
<span><span class="co">#&gt; - Best parameter: 2.02 4.27 -1.45 -0.83 -0.63</span></span>
<span><span class="co">#&gt; - Best value: 276.36</span></span></code></pre></div>
</div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Bonnans:2006" class="csl-entry">
Bonnans, J.-F., J. C. Gilbert, C. Lemaréchal, and C. A. Sagastizábal.
2006. <em>Numerical Optimization: Theoretical and Practical
Aspects</em>. Springer Science &amp; Business Media.
</div>
<div id="ref-Chang:2021" class="csl-entry">
Chang, W. 2021. <em>R6: Encapsulated Classes with Reference
Semantics</em>. <a href="https://CRAN.R-project.org/package=R6" class="external-link">https://CRAN.R-project.org/package=R6</a>.
</div>
<div id="ref-Dempster:1977" class="csl-entry">
Dempster, A. P., N. M. Laird, and D. B. Rubin. 1977. <span>“Maximum
Likelihood from Incomplete Data via the EM Algorithm.”</span>
<em>Journal of the Royal Statistical Society: Series B</em> 39 (1):
1–22.
</div>
<div id="ref-Nocedal:2006" class="csl-entry">
Nocedal, J., and S. J. Wright. 2006. <span>“Quadratic
Programming.”</span> <em>Numerical Optimization</em>, 448–92.
</div>
<div id="ref-Oelschläger:2023" class="csl-entry">
Oelschläger, L., and M. Ötting. 2023. <em>optimizeR: Unified Framework
for Numerical Optimizer</em>. <a href="https://CRAN.R-project.org/package=optimizeR" class="external-link">https://CRAN.R-project.org/package=optimizeR</a>.
</div>
<div id="ref-Shireman:2017" class="csl-entry">
Shireman, E., D. Steinley, and M. J. Brusco. 2017. <span>“Examining the
Effect of Initialization Strategies on the Performance of Gaussian
Mixture Modeling.”</span> <em>Behavior Research Methods</em> 49 (1):
282–93.
</div>
<div id="ref-Wickham:2019" class="csl-entry">
Wickham, H. 2019. <em>Advanced <span>R</span></em>. CRC press. <a href="https://doi.org/10.1201/9781351201315" class="external-link">https://doi.org/10.1201/9781351201315</a>.
</div>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by <a href="https://loelschlaeger.de" class="external-link">Lennart Oelschläger</a>, <a href="https://www.uni-bielefeld.de/fakultaeten/wirtschaftswissenschaften/lehrbereiche/stats/team/marius-otting-(m.sc.)/" class="external-link">Marius Ötting</a>, <a href="https://de.wikipedia.org/wiki/Dietmar_Bauer" class="external-link">Dietmar Bauer</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
