---
title: "Example: Hidden Markov Model"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEncoding{UTF-8}
  %\VignetteIndexEntry{Example: Hidden Markov Model}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.dim = c(8, 6),
  out.width = "100%"
)
```

```{r setup}
library("ino") 
options(ino_progress = FALSE)
library("ggplot2")
```

This vignette^[The vignette was build using R `r paste(R.Version()[6:7], collapse = ".")` with the {ino} `r utils::packageVersion("ino")` package.] describes the workflow of the {ino} package for the likelihood optimization of an hidden Markov model (HMM). The aim of this vignette is to learn about the functions and the workflow of ino, for more technical details about HMMs see, e.g.,  Zucchini et al. (2016).

## Data

The example data set considered throughout this vignette covers a series of earthquake counts. The data set is also included in the ino package.

```{r}
data("earthquakes")
ggplot(earthquakes, aes(x = year, y = obs)) +
  geom_point() + geom_line() + ylab("count")
```

As the observations are unbounded counts, we consider a Poisson-HMM. The (log-)likelihood of a Poisson-HMM is given by the function `f_ll_hmm()`.

## Model fitting

We consider an 2-state HMM (`N = 2`) with four parameters (`npar = 4`) to be estimated. Two parameters are required for the transition probability matrix (tpm), and another two correspond to the state-dependent Poisson means. `neg =  TRUE` indicates that we minimize the negative log-likelihood.  

```{r}
hmm_ino <- setup_ino(
  f = ino:::f_ll_hmm,
  npar = 4,
  data = ino::earthquakes,
  N = 2,
  neg = TRUE,
  opt = set_optimizer_nlm(),
  verbose = FALSE)
```

### Random initialization

We first use randomly chosen starting values. 

```{r}
for(i in 1:3)
  hmm_ino <- random_initialization(hmm_ino)
```


### Fixed initialization

For choosing fixed starting values, we set the two values for the tpm to -2, corresponding to probabilities to stay in state 1 and 2 of about 0.88 (note that we employ a multinomial logit link here to ensure that the probabilities are between 0 and 1). For the Poisson means, we consider values close to 15 and 25, as most counts fall in this region (note here that we exponentiate the means in the likelihood as they are constrained to be positive). We consider the following three sets of starting values:

```{r}
at <- list(c(-2, -2, log(20), log(40)), 
           c(-2, -2, log(15), log(25)),
           c(-2, -2, log(10), log(20)))
for(i in 1:3)
  hmm_ino <- fixed_initialization(hmm_ino, at = at[[i]])
```

### Subset initialization

To illustrate the subset initialization strategy, we fit the 2-state HMM to the first half of the time series (`prop = 0.5`). The starting values for this subset are chosen randomly. The model is then fitted again to the entire sample using the estimates obtained for the subset as initial values.

```{r}
# hmm_ino <- subset_initialization(
#     hmm_ino, arg = "data", how = "first", prop = 0.5,
#     initialization = random_initialization()
#     )
```


## Evaluating the optimization runs

### Local optima

Selecting the starting values for HMMs is a well-known issue, as poor starting values may likely result in local maxima. Other R packages designed to fit HMMs discuss this topic in more detail (see, e.g., https://cran.r-project.org/web/packages/moveHMM/vignettes/moveHMM-starting-values.pdf). We thus first evaluate the optimizations by comparing the likelihood values at convergence, which can be plotted using `overview_optima()`:

```{r}
overview_optima(hmm_ino)
```

The frequency table indicates that `r overview_optima(hmm_ino)[1,2]` runs converged to the same likelihood value (`r as.numeric(as.character(overview_optima(hmm_ino)[1,1]))`), which is the global maximum (note these are the negative log-likelihood values).  

When comparing the likelihood values across the strategies, we see that the random starting values did sometimes result in a local maximum:

```{r}
plot(hmm_ino, var = "minimum", by = ".strategy", type = "barplot")
```

Using `summary`, we can investigate all optimization runs:

```{r}
summary(hmm_ino, group = NULL)
```

The table further indicates that (e.g.) the fourth optimization converged to the global optimum. We can extract the corresponding initial values and estimates as follows:

```{r}
hmm_ino$runs$pars[[4]]
```


### Optimization time

We use the `plot()` function to investigate the computation time. Intuitively, the optimization runs with fixed starting values should be faster than with random starting values, since we have carefully chosen the fixed starting values by investigating the data. The boxplots confirm this intuition: 

```{r}
plot(hmm_ino, var = ".time", by = ".strategy")
```

