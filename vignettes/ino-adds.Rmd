



### Standardizing the optimization problem

In some situations, it is possible to consider a standardized version of the optimization problem, which could potentially improve the performance of the numerical optimizer. In our example, we can standardize the data before running the optimization via the `$standardize()` method:

```{r, standardize data}
Nop_mixture$standardize("data")
str(Nop_mixture$get_argument("data"))
```

To optimize the likelihood using the standardized data set, we again use `$optmize()`, which by default uses random starting values. Below, we will compare these results with those obtained on the original optimization problem. 

```{r, optimization with standardized data}
Nop_mixture$
  optimize(runs = 100, label = "data_standardized")$
  reset_argument("data")
```

The usage of `$reset_argument("data")` is important: to perform further optimization runs after having applied standardized initialization, we undo the standardization of the data and obtain the original data set. If we would not use `$reset_argument()`, all further optimization runs will be carried out on the standardized data set. 

### Reducing the optimization problem

In some situations, it is possible to first optimize a sub-problem and use those results as an initialization for the full optimization problem. For example, in the context of likelihood maximization, if the data set considered shows some complex structures or is very large, numerical optimization may become computationally costly. In such cases, it can be beneficial to initially consider a reduced data set. The following application of the `$reduce()` method transforms `"data"` by selecting a proportion of 30\% data points at random:

```{r, reduce data}
Nop_mixture$reduce(argument_name = "data", how = "random", prop = 0.3, seed = 1)
str(Nop_mixture$get_argument("data"))
```

Similar to the standardizing above, calling `$optimize()` now optimizes on the reduced data set:

```{r, optimization with reduced data}
Nop_mixture$
  optimize(runs = 100, label = "data_subset")$
  reset_argument("data")$
  continue()
```

Again, we use `$reset_argument("data")` to obtain the original data set. The `$continue()` method now optimizes on the whole data set using the estimates obtained on the reduced data as initial values.

In addition to selecting sub samples at random (`how = "random"`), four other options exist via specifying the argument `how`:

- `"first"` selects the top data points,
- `"last"` selects the last data points,
- `"similar` selects similar data points based on k-means clustering,
- `"dissimilar"` is similar to `"similar"` but selects dissimilar data points.



